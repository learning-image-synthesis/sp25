---
type: lecture
date: 2024-04-03T16:00:00-05:00
title: "3D-aware Synthesis (part II)"
thumbnail: "/static_files/lectures/EG3D.png"
tldr: "Synthesizing an image of a certain object category from different camera viewpoints"
hide_from_announcments: true
links:
    - url: "https://learning-image-synthesis.github.io/sp25/lectures/"
      name: pdf
    - url: "https://learning-image-synthesis.github.io/sp25/lectures/"
      name: pptx
---
Reading List:
- [GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis, Schwarz et al, NeurIPS 2020](https://arxiv.org/abs/2007.02442)
- [pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis, Chan et al, CVPR 2021](https://arxiv.org/pdf/2012.00926.pdf)
- [Editing Conditional Radiance Fields, Liu et al, ICCV 2021](http://editnerf.csail.mit.edu/paper.pdf)
- [EG3D: Efficient Geometry-aware 3D Generative Adversarial Networks, Chan et al, arXiv 2021](https://arxiv.org/abs/2112.07945)
- [StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis, Gu et al, arXiv 2021](https://arxiv.org/abs/2110.08985)
- [DreamFusion: Text-to-3D using 2D Diffusion, Ben Poole et al., ICLR 2023](https://dreamfusion3d.github.io/)
- [Instruct-NeRF2NeRF: Editing 3D Scenes with Instructions, Haque et al., arXiv 2023](https://instruct-nerf2nerf.github.io/)