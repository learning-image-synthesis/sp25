---
type: lecture
date: 2025-02-26W09:30:00-05:00
title: "Image-to-Image Translation and Conditional Generative Models (part II)"
thumbnail: "/static_files/lectures/horse2zebra.jpg"
hide_from_announcments: true
links:
    - url: "https://learning-image-synthesis.github.io/sp25/lectures/"
      name: pdf
    - url: "https://learning-image-synthesis.github.io/sp25/lectures/"
      name: pptx
---
Reading List:
- [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, Zhu et al, ICCV 2017](https://arxiv.org/abs/1703.10593)
- [Unsupervised Image-to-Image Translation Networks, Liu et al., NeurIPS 2017](https://arxiv.org/abs/1703.00848)
- [Learning from Simulated and Unsupervised Images through Adversarial Training, Shrivastava et al, CVPR 2017](https://arxiv.org/abs/1612.07828)
- [Multimodal Unsupervised Image-to-Image Translation, Huang et al., ECCV 2018](https://arxiv.org/abs/1804.04732)
- [SDEdit: Guided Image Synthesis and Editing with Stochastic Differential Equations, Meng et al., ICLR 2022](https://arxiv.org/abs/2108.01073)
- [Adding Conditional Control to Text-to-Image Diffusion Models, Zhang et al., ICCV 2024](https://arxiv.org/abs/2302.05543)
